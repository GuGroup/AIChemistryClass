{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d2de8d-aae3-4d90-b742-a29ac9d97539",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "This is the paper that contains the data that we will use to develop our model. If you are interested, have a look!\n",
    "\n",
    "Automated image segmentation of scanning electron microscopy images of graphene using U-Net Neural Network\n",
    "\n",
    "Aagam Shah, Joshua A. Schiller, Isiah Ramos, James Serrano, Darren K. Adams, Sameh Tawfick, Elif Ertekin\n",
    "Materials Today Communications. Volume 35, June 2023, 106127\n",
    "https://doi.org/10.1016/j.mtcomm.2023.106127\n",
    "\n",
    "\n",
    "The paper is about using the CNN to identify graphene in scanning electron microscope images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4efd7-beb4-4831-ae45-f24b0f9ab1c0",
   "metadata": {},
   "source": [
    "### Data Example\n",
    "We have already prepared a data for you to download. Run the following code block to download the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314a734-86c2-49f2-9dee-aaee034a7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "im = Image.open(sorted(glob('./data/*/*.tif'))[0])\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970f1ad-8890-4a67-be3b-c521c26fd510",
   "metadata": {},
   "source": [
    "This is an SEM image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1806ce8b-4de9-484f-b29a-533e08251c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(sorted(glob('./data/*/*.png'))[0])\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed2d84-b23a-4b2c-9a90-6625484d427a",
   "metadata": {},
   "source": [
    "The light pixel has the value of 1 and dark pixel has the value of 0, indicating the whether there is a graphene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ee1c0-c5af-44b9-87ee-492e4d2c38a4",
   "metadata": {},
   "source": [
    "## Homework part (a)\n",
    "Instruction:\\\n",
    "Make a Dataset class to load the data.\\\n",
    "HINT: Have a look at HW13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b07ea0-37a9-45bb-853f-b8b219a7d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "class ImageData(Dataset):\n",
    "    def __init__(self):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for p in glob('./data/*.tif'):\n",
    "            im = Image.open(p)\n",
    "            x = np.array(im)\n",
    "            im = Image.open(p.replace('image_','image_mask_')[:-3]+'png')\n",
    "            y = np.array(im)\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        X = torch.Tensor(np.array(X))\n",
    "        Y = torch.Tensor(np.array(Y))\n",
    "        self.X = X[:,None,:,:]/255 # data_idx * C * H * W\n",
    "        self.Y = Y[:,None,:,:]/255 # data_idx * C * H * W\n",
    "        self.X = self.X.to('cuda') # if you want to use GPU, uncomment this\n",
    "        self.Y = self.Y.to('cuda') # if you want to use GPU, uncomment this\n",
    "        \n",
    "    def __len__(self):\n",
    "        ##################### Fill in here #####################\n",
    "        number_of_data = self.X.shape[0]\n",
    "        ##################### Fill in here #####################\n",
    "        return number_of_data\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        ##################### Fill in here #####################\n",
    "        x = self.X[idx,:,:,:]\n",
    "        y = self.Y[idx,:,:,:]\n",
    "        ##################### Fill in here #####################\n",
    "        return x,y\n",
    "data = ImageData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff64590-8f3e-40b7-b282-c436ffb173ee",
   "metadata": {},
   "source": [
    "## Homework part (b)\n",
    "Instruction:\\\n",
    "Randomly split your data into train, validation and test by 80, 10, and 10 percent.\n",
    "HINT: Have a look at HW13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e369fec-703f-40c3-bbc4-da27eed2519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, data_test = random_split(data,[0.80,0.1,0.1])  ####### Fill in here #######"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5e867-893a-4924-9474-8412207c375c",
   "metadata": {},
   "source": [
    "## Homework part (c)\n",
    "Instruction:\n",
    "Calculate the feature and output mean and standard deviation using the training set, and apply the normalization to all data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7fd64-84f6-4e3a-9d29-1cb1e9c2fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for x,y in data_train:\n",
    "    X_train.append(x)\n",
    "X_train = torch.stack(X_train)\n",
    "##################### Fill in here #####################\n",
    "Xmean = X_train.mean()\n",
    "Xstd = X_train.std()\n",
    "##################### Fill in here #####################\n",
    "data.X = (data.X-Xmean)/Xstd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c5581-8622-4ff4-be83-f01fa1230a0d",
   "metadata": {},
   "source": [
    "## Homework part (d)\n",
    "Instruction:\\\n",
    "Construct a CNN where the hidden layet has 16 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994263a-6ca5-44a6-99b3-cdee441412bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ####### Fill in here #######\n",
    "        self.L1 = torch.nn.Conv2d(1, 16, (5,5), padding=2)\n",
    "        self.L2 = torch.nn.Conv2d(16, 1, (5,5), padding=2)\n",
    "        self.act1 = nn.ReLU()\n",
    "    def forward(self, X):\n",
    "        ####### Fill in here #######\n",
    "        Z1 = self.L1(X)\n",
    "        A1 = self.act1(Z1)\n",
    "        Z2 = self.L2(A1)\n",
    "        return Z2\n",
    "        \n",
    "NN = Model()\n",
    "NN = NN.to('cuda') # if you want to use GPU, uncomment this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ebcb4-5f7d-405c-bc6e-188576c81ae0",
   "metadata": {},
   "source": [
    "The code below will train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05e5df-452b-438d-b0b3-f8b1064f9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(data_train, batch_size=128, shuffle=True)\n",
    "dataloader_val = DataLoader(data_val, batch_size=128, shuffle=True)\n",
    "dataloader_test = DataLoader(data_test, batch_size=128, shuffle=True)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(NN.parameters(),0.01, weight_decay = 0.01)\n",
    "min_val_loss = torch.Tensor([float('Inf')])\n",
    "train_loss_at_min_val_loss = torch.Tensor([float('Inf')])\n",
    "min_val_loss = min_val_loss.to('cuda') # if you want to use GPU, uncomment this\n",
    "for i in range(100): \n",
    "    train_loss = 0\n",
    "    for X, Y in dataloader_train:\n",
    "        yhat= NN(X)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(yhat,Y)\n",
    "        loss.backward()\n",
    "        train_loss += loss*Y.shape[0]\n",
    "        optimizer.step()\n",
    "    train_loss = train_loss/len(data_train)\n",
    "    loss_val = 0\n",
    "    for X, Y in dataloader_val:\n",
    "        yhat = NN(X)\n",
    "        loss_val += criterion(yhat,Y)*Y.shape[0]\n",
    "    loss_val = loss_val/len(data_val)\n",
    "\n",
    "    print(f'{i+1} epoch. train loss: {train_loss:.3f}, val loss: {loss_val:.3f}',end='')\n",
    "    if loss_val < min_val_loss:\n",
    "        torch.save(NN.state_dict(),'best.pth.tar')\n",
    "        min_val_loss = loss_val\n",
    "        train_loss_at_min_val_loss = train_loss\n",
    "        print('<-new best',end='')\n",
    "    print('')\n",
    "print(f'Best model: train_loss {train_loss_at_min_val_loss:.3f} val_loss {min_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758645dc-7a69-40ec-b678-0ddae809b7d2",
   "metadata": {},
   "source": [
    "The code below is used for testing the model with test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ba378-7f4f-4e32-93d5-edd8540554af",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.load_state_dict(torch.load('best.pth.tar'))\n",
    "YTest = []\n",
    "YhatTest = []\n",
    "for X, Y in dataloader_test:\n",
    "    yhat = NN(X)\n",
    "    YTest.append(Y)\n",
    "    YhatTest.append(yhat)\n",
    "YTest = torch.cat(YTest)\n",
    "YhatTest = torch.cat(YhatTest)\n",
    "print(f'Accuracy: {torch.mean((torch.round(torch.sigmoid(YhatTest))==YTest).double()):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f87ee5-c466-4cd0-95d8-89795da6476b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
