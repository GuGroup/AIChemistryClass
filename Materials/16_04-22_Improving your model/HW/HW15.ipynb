{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e318f4cc-4430-460e-86b4-a1fb71f24b7a",
      "metadata": {
        "id": "e318f4cc-4430-460e-86b4-a1fb71f24b7a"
      },
      "source": [
        "### Dataset\n",
        "This is the paper that contains the data that we will use to develop our model. If you are interested, have a look!\n",
        "\n",
        "Statistical Analysis and Discovery of Heterogeneous Catalysts Based on Machine Learning from Diverse Published Data\n",
        "\n",
        "\n",
        "Keisuke Suzuki, Dr. Takashi Toyao, Dr. Zen Maeno, Dr. Satoru Takakusagi, Prof. Ken-ichi Shimizu, Dr. Ichigaku Takigaw\n",
        "aVolume1 1, Issue 18,\n",
        "September 19, 20,\n",
        "\n",
        "Pages\n",
        "\n",
        " 2019 https://doi.org/10.1002/cctc.201900952\n",
        "\n",
        "Data paper contains information about the catalyst preparation methods, and the values that needs to be predicted which is the yield of C2 products"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f4efd7-beb4-4831-ae45-f24b0f9ab1c0",
      "metadata": {
        "id": "56f4efd7-beb4-4831-ae45-f24b0f9ab1c0"
      },
      "source": [
        "### Loading the data\n",
        "We have already prepared a data for you to download. Run the following code block to download the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1314a734-86c2-49f2-9dee-aaee034a7d1c",
      "metadata": {
        "id": "1314a734-86c2-49f2-9dee-aaee034a7d1c"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://github.com/GuGroup/NNTutorial-2024-02-11-Winter-camp/raw/main/4NNExampleMaterials/OCM_matrix.csv\", \"OCM_matrix.csv\")\n",
        "import csv\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "df = pd.read_csv('OCM_matrix.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c202bfa2-6850-4332-b336-491124119686",
      "metadata": {
        "id": "c202bfa2-6850-4332-b336-491124119686"
      },
      "source": [
        "The first column Y(C2),% is the value we want to predict (y), and the rest of the columns are the features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9ee1c0-c5af-44b9-87ee-492e4d2c38a4",
      "metadata": {
        "id": "cc9ee1c0-c5af-44b9-87ee-492e4d2c38a4"
      },
      "source": [
        "## Homework part (a)\n",
        "Instruction:\\\n",
        "Make a Dataset class to load the data.\\\n",
        "HINT: Have a look at HW13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b07ea0-37a9-45bb-853f-b8b219a7d2ac",
      "metadata": {
        "id": "f4b07ea0-37a9-45bb-853f-b8b219a7d2ac"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "class CatalystData(Dataset):\n",
        "    def __init__(self, path='OCM_matrix.csv'):\n",
        "        ####### Fill in here #######\n",
        "\n",
        "\n",
        "\n",
        "        ####### Fill in here #######\n",
        "\n",
        "    def __len__(self):\n",
        "        ####### Fill in here #######\n",
        "\n",
        "        ####### Fill in here #######\n",
        "        return number_of_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ####### Fill in here #######\n",
        "\n",
        "\n",
        "        ####### Fill in here #######\n",
        "        return x,y\n",
        "data = CatalystData('OCM_matrix.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ff64590-8f3e-40b7-b282-c436ffb173ee",
      "metadata": {
        "id": "2ff64590-8f3e-40b7-b282-c436ffb173ee"
      },
      "source": [
        "## Homework part (b)\n",
        "Instruction:\\\n",
        "Randomly split your data into train, validation and test by 80, 10, and 10 percent.\n",
        "HINT: Have a look at HW13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e369fec-703f-40c3-bbc4-da27eed2519d",
      "metadata": {
        "id": "8e369fec-703f-40c3-bbc4-da27eed2519d"
      },
      "outputs": [],
      "source": [
        "data_train, data_val, data_test =  ####### Fill in here #######"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14d5e867-893a-4924-9474-8412207c375c",
      "metadata": {
        "id": "14d5e867-893a-4924-9474-8412207c375c"
      },
      "source": [
        "## Homework part (c)\n",
        "Instruction:\n",
        "Calculate the feature and output mean and standard deviation using the training set, and apply the normalization to all data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a7fd64-84f6-4e3a-9d29-1cb1e9c2fb3a",
      "metadata": {
        "id": "f3a7fd64-84f6-4e3a-9d29-1cb1e9c2fb3a"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "for x,y in data_train:\n",
        "    X_train.append(x)\n",
        "    Y_train.append(y)\n",
        "X_train = torch.stack(X_train)\n",
        "Y_train = torch.stack(Y_train)\n",
        "####### Fill in here #######\n",
        "Xmean =\n",
        "Xstd =\n",
        "Ymean =\n",
        "Ystd =\n",
        "####### Fill in here #######\n",
        "Xstd[Xstd == 0] = 1 # to prevent division by zero\n",
        "data.X = (data.X-Xmean)/Xstd\n",
        "data.Y = (data.Y-Ymean)/Ystd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca1c5581-8622-4ff4-be83-f01fa1230a0d",
      "metadata": {
        "id": "ca1c5581-8622-4ff4-be83-f01fa1230a0d"
      },
      "source": [
        "## Homework part (d)\n",
        "Instruction:\\\n",
        "Construct a simple neural network of your choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0994263a-6ca5-44a6-99b3-cdee441412bb",
      "metadata": {
        "id": "0994263a-6ca5-44a6-99b3-cdee441412bb"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,####### Fill in here #######):\n",
        "        super().__init__()\n",
        "        ####### Fill in here #######\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ####### Fill in here #######\n",
        "    def forward(self, X):\n",
        "        ####### Fill in here #######\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ####### Fill in here #######\n",
        "        return Z2\n",
        "\n",
        "NN = Model(####### Fill in here #######)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8ebcb4-5f7d-405c-bc6e-188576c81ae0",
      "metadata": {
        "id": "ab8ebcb4-5f7d-405c-bc6e-188576c81ae0"
      },
      "source": [
        "## Homework part (e)\n",
        "Instruction:\\\n",
        "\"weight_decay\" of the line below is the key argument for the lambda (regularization strength) of the L2 norm.\\\n",
        "optimizer = torch.optim.Adam(NN.parameters(),0.001, weight_decay = 0.001)\\\n",
        "Modify the training code below to perform the optimal lambda parameter search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f05e5df-452b-438d-b0b3-f8b1064f9c60",
      "metadata": {
        "id": "3f05e5df-452b-438d-b0b3-f8b1064f9c60"
      },
      "outputs": [],
      "source": [
        "dataloader_train = DataLoader(data_train, batch_size=128, shuffle=True)\n",
        "dataloader_val = DataLoader(data_val, batch_size=128, shuffle=True)\n",
        "dataloader_test = DataLoader(data_test, batch_size=128, shuffle=True)\n",
        "criterion = torch.nn.MSELoss()\n",
        "####### You will have to modify code here (and other places as well) #######\n",
        "optimizer = torch.optim.Adam(NN.parameters(),0.001, weight_decay = 0.001)\n",
        "\n",
        "####### You will have to modify code here (and other places as well) #######\n",
        "min_val_loss = torch.Tensor([float('Inf')])\n",
        "train_loss_at_min_val_loss = torch.Tensor([float('Inf')])\n",
        "for i in range(100):\n",
        "    train_loss = 0\n",
        "    for X, Y in dataloader_train:\n",
        "        yhat= NN(X)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat,Y)\n",
        "        loss.backward()\n",
        "        train_loss += loss*Y.shape[0]\n",
        "        optimizer.step()\n",
        "    train_loss = train_loss/len(data_train)\n",
        "    loss_val = 0\n",
        "    for X, Y in dataloader_val:\n",
        "        yhat = NN(X)\n",
        "        loss_val += criterion(yhat,Y)*Y.shape[0]\n",
        "    loss_val = loss_val/len(data_val)\n",
        "\n",
        "    if loss_val < min_val_loss:\n",
        "        torch.save(NN.state_dict(),'best.pth.tar')\n",
        "        min_val_loss = loss_val\n",
        "        train_loss_at_min_val_loss = train_loss\n",
        "print(f'Best model: train_loss {train_loss_at_min_val_loss:.3f} val_loss {min_val_loss:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "758645dc-7a69-40ec-b678-0ddae809b7d2",
      "metadata": {
        "id": "758645dc-7a69-40ec-b678-0ddae809b7d2"
      },
      "source": [
        "The code below is used for testing the model with test set.\n",
        "How is your model performance?\n",
        "The RMSE of the best model in the paper is 4.15. Is your model better than the paper?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "550ba378-7f4f-4e32-93d5-edd8540554af",
      "metadata": {
        "id": "550ba378-7f4f-4e32-93d5-edd8540554af"
      },
      "outputs": [],
      "source": [
        "loss_test = 0\n",
        "NN.load_state_dict(torch.load('best.pth.tar'))\n",
        "YTest = []\n",
        "YhatTest = []\n",
        "for X, Y in dataloader_test:\n",
        "    yhat = NN(X)\n",
        "    loss_test += criterion(yhat,Y)*Y.shape[0]\n",
        "    YTest.append(Y)\n",
        "    YhatTest.append(yhat)\n",
        "loss_test = loss_test/len(data_test)\n",
        "print(f'Mean squared error: {loss_test:.3f}')\n",
        "YTest = torch.cat(YTest)\n",
        "YhatTest = torch.cat(YhatTest)\n",
        "YTest = YTest*Ystd+Ymean\n",
        "YhatTest = YhatTest*Ystd+Ymean\n",
        "print(f'Mean absolute error after denormalizatoin: {torch.mean(torch.abs(YTest-YhatTest)):.3f}')\n",
        "print(f'Root mean squared error after denormalization: {torch.sqrt(loss_test*Ystd)[0]:.3f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}