{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d2de8d-aae3-4d90-b742-a29ac9d97539",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "This is the paper that contains properties of ~134k organic molecules with up to 9 heavy atoms (C,N,O,F).\n",
    "\n",
    "Quantum chemistry structures and properties of 134 kilo molecules\r\n",
    "Raghunathan Ramakrishnan, Pavlo O. Dral, Matthias Rupp & O. Anatole von Lilienfel\n",
    "Scientific Data volume 1, Article number: 140022 (2014) d\n",
    "https://www.nature.com/articles/sdata201422\n",
    "\n",
    "We will use simple GCNN to predict Gibbs free energy of the molecules.\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d98e6f-9032-4aa6-baa9-331da5ebdb66",
   "metadata": {},
   "source": [
    "### Program to install\n",
    "For graph convolution, we will need to install extra package. You need to install torch_geometric and rdkit.\n",
    "\n",
    "On Google Colab, you can use the following command for rdkit:\n",
    "\n",
    "!pip install rdkit\n",
    "\n",
    "For CPU,\n",
    "\n",
    "!pip install torch_geometric pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
    "\n",
    "For CUDA 11.8,\n",
    "\n",
    "!pip install torch_geometric pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cu118.html\n",
    "\n",
    "For CUDA 12.1,\n",
    "\n",
    "!pip install torch_geometric pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "\n",
    "Please check the official pytorch geometric website for the install instruction: https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4efd7-beb4-4831-ae45-f24b0f9ab1c0",
   "metadata": {},
   "source": [
    "### Data Example\n",
    "In the class you should have downloaded the SmilesAndG.json. Let's open it and utilize rdkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314a734-86c2-49f2-9dee-aaee034a7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open('SmilesAndG.json'))\n",
    "d = data[100]\n",
    "print(f'Smiles of the 100th data is {d[0]}')\n",
    "print(f'This smiles has a Gibbs free energy of {d[1]} Hatree (Ha; 1 Ha = 2625.5 kJ/mol)')\n",
    "print('Below shows the structure')\n",
    "from rdkit import Chem\n",
    "Chem.MolFromSmiles(d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218c59e-0385-4b8d-9be8-cd2480063b4d",
   "metadata": {},
   "source": [
    "## Homework part (a) Define a featurization scheme\n",
    "Instruction:\n",
    "\n",
    "Below is the processing method for converting the data. Fill in the gap below to create one hot encoding features for atom and edges. The list of column attributes are written in unique_atoms and unique_bonds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390274ab-a519-49f0-b7e2-ee5789e3f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "unique_atoms = ['H','C','N','O','F']\n",
    "unique_bonds = ['SINGLE', 'DOUBLE', 'TRIPLE', 'AROMATIC']\n",
    "def ProcessDatum(d):\n",
    "    mol = Chem.MolFromSmiles(d[0]) \n",
    "    mol = Chem.AddHs(mol)\n",
    "    v = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        ######################## Fill in here ########################\n",
    "        oh = [0 for _ in unique_atoms]\n",
    "        oh[unique_atoms.index(atom.GetSymbol())] = 1\n",
    "        ######################## Fill in here ########################\n",
    "        v.append(oh)\n",
    "    v = torch.tensor(v,dtype=torch.float)\n",
    "    c = []\n",
    "    e = []\n",
    "    for bond in mol.GetBonds():\n",
    "        c.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "        c.append([bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]) # torch_geometric requires bi_directional graph\n",
    "        ######################## Fill in here ########################\n",
    "        oh = [0 for _ in unique_bonds]\n",
    "        oh[unique_bonds.index(str(bond.GetBondType()))] = 1\n",
    "        ######################## Fill in here ########################\n",
    "        e.append(oh)\n",
    "        e.append(oh)\n",
    "    c = torch.tensor(c,dtype=torch.long).T # torch wants transposed matrix\n",
    "    e = torch.tensor(e,dtype=torch.float)\n",
    "    y = torch.tensor([d[1]*2625.5]) # convert to kJ/mol\n",
    "    return v,e,c,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ee1c0-c5af-44b9-87ee-492e4d2c38a4",
   "metadata": {},
   "source": [
    "## Homework part (b)\n",
    "Instruction:\n",
    "\n",
    "Use the torch_geometric.data.Data to make a graph datum in the Fill in here. The information is in the lecture as well as the torch_geometric website (https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html#data-handling-of-graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b07ea0-37a9-45bb-853f-b8b219a7d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SmilesData(Dataset):\n",
    "    def __init__(self, root='./'):\n",
    "        super().__init__(root, transform=None, pre_transform=None, pre_filter=None)\n",
    "        data = json.load(open(os.path.join(root,'SmilesAndG.json')))\n",
    "        self.data = []\n",
    "        for d in tqdm(data):\n",
    "            v,e,c,y = ProcessDatum(d)\n",
    "            ######################## Fill in here ########################\n",
    "            datum = Data(x=v,edge_index=c,edge_attr=e,y_raw=y)\n",
    "            ######################## Fill in here ########################\n",
    "            self.data.append(datum)\n",
    "        # The training is significantly better if atomic contribution is calculated and subtracted.\n",
    "        x = []\n",
    "        y_raw = []\n",
    "        for d in self.data:\n",
    "            x.append(d.x.sum(0))\n",
    "            y_raw.append(d.y_raw)\n",
    "        x = torch.stack(x)\n",
    "        y_raw = torch.cat(y_raw)\n",
    "        self.atomistic_contribution = torch.linalg.lstsq(x,y_raw).solution\n",
    "        y_raw = y_raw - x@self.atomistic_contribution\n",
    "        for d,yy in zip(self.data,y_raw):\n",
    "            d.y_raw = yy\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data[idx]\n",
    "Dataset = SmilesData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff64590-8f3e-40b7-b282-c436ffb173ee",
   "metadata": {},
   "source": [
    "The following code randomly split the data into 80% train, 10% validation and 10% test. The output mean and standard deviation using the training set, and is used to apply the normalization to all data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e369fec-703f-40c3-bbc4-da27eed2519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "data_train, data_val, data_test = random_split(Dataset,[0.80,0.1,0.1])\n",
    "Y_train = []\n",
    "for d in data_train:\n",
    "    Y_train.append(d.y_raw)\n",
    "Y_train = torch.stack(Y_train)\n",
    "Ymean = Y_train.mean(0)\n",
    "Ystd = Y_train.std(0)\n",
    "for d in Dataset:\n",
    "    d.y = (d.y_raw-Ymean)/Ystd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c5581-8622-4ff4-be83-f01fa1230a0d",
   "metadata": {},
   "source": [
    "## Homework part (c)\n",
    "Here we will use CGCNN convolution layer \n",
    "\n",
    "<img src=\"https://journals.aps.org/prl/article/10.1103/PhysRevLett.120.145301/figures/1/medium\">\n",
    "\n",
    "The atom and edge features are first \"embedded\" through linear layer which means that the features are converted to latent vectors. Then, the atom features will be updated according to the crystal graph convolution introduced during the class.\n",
    "\n",
    "torch_geometric already has CGConv with input argument:\n",
    "- channels (int) -  feature size of atom\n",
    "- dim (int) - feature size of edge\n",
    "- aggr (int) - aggregation method (add, mean, max)\n",
    "- batch_norm (bool) - whether or not peform batch normalization\n",
    "\n",
    "Instruction:\n",
    "\n",
    "Here we already have the code to embed the atom and edge feature. Fill the blank to implement the CGCNN convonlution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994263a-6ca5-44a6-99b3-cdee441412bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import CGConv\n",
    "from torch_geometric.nn.pool import global_mean_pool\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.atom_embedding = nn.Linear(5,16)\n",
    "        self.edge_embedding = nn.Linear(4,16)\n",
    "        ######################## Fill in here ########################\n",
    "        self.conv1 = CGConv(channels=16,dim=16,aggr='mean',batch_norm=True)\n",
    "        self.conv2 = CGConv(channels=16,dim=16,aggr='mean',batch_norm=True)\n",
    "        ######################## Fill in here ########################\n",
    "        self.out_linear = nn.Linear(16,1)\n",
    "    def forward(self, batch):\n",
    "        v, edge_index, e = batch.x, batch.edge_index, batch.edge_attr\n",
    "        v = self.atom_embedding(v)\n",
    "        e = self.edge_embedding(e)\n",
    "        v = self.conv1(x=v, edge_index=edge_index,edge_attr=e)\n",
    "        v = self.conv2(x=v, edge_index=edge_index,edge_attr=e)\n",
    "        v = self.out_linear(v)\n",
    "        y = global_mean_pool(v,batch.batch)\n",
    "        return y.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ebcb4-5f7d-405c-bc6e-188576c81ae0",
   "metadata": {},
   "source": [
    "The code below will train your model and perform testing with test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05e5df-452b-438d-b0b3-f8b1064f9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "dataloader_train = DataLoader(data_train, batch_size=128, shuffle=True)\n",
    "dataloader_val = DataLoader(data_val, batch_size=128, shuffle=True)\n",
    "dataloader_test = DataLoader(data_test, batch_size=128, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),0.01)\n",
    "min_val_loss = torch.Tensor([float('Inf')])\n",
    "train_loss_at_min_val_loss = torch.Tensor([float('Inf')])\n",
    "min_val_loss = min_val_loss.to(device)\n",
    "for i in range(100): \n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch in dataloader_train:\n",
    "        batch = batch.to(device)\n",
    "        yhat= model(batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(yhat,batch.y)\n",
    "        loss.backward()\n",
    "        train_loss += loss*len(batch)\n",
    "        optimizer.step()\n",
    "    train_loss = train_loss/len(data_train)\n",
    "    loss_val = 0\n",
    "    model.eval()\n",
    "    for batch in dataloader_val:\n",
    "        batch = batch.to(device)\n",
    "        yhat = model(batch)\n",
    "        loss_val += criterion(yhat,batch.y)*len(batch)\n",
    "    loss_val = loss_val/len(data_val)\n",
    "\n",
    "    print(f'{i+1} epoch. train loss: {train_loss:.3f}, val loss: {loss_val:.3f}',end='')\n",
    "    if loss_val < min_val_loss:\n",
    "        torch.save(model.state_dict(),'best.pth.tar')\n",
    "        min_val_loss = loss_val\n",
    "        train_loss_at_min_val_loss = train_loss\n",
    "        print('<-new best',end='')\n",
    "    print('')\n",
    "print(f'Best model: train_loss {train_loss_at_min_val_loss:.3f} val_loss {min_val_loss:.3f}')\n",
    "\n",
    "model.load_state_dict(torch.load('best.pth.tar'))\n",
    "model.eval()\n",
    "YTest = []\n",
    "YhatTest = []\n",
    "for batch in dataloader_test:\n",
    "    batch = batch.to(device)\n",
    "    yhat = model(batch)\n",
    "    YTest.append(batch.y)\n",
    "    YhatTest.append(yhat)\n",
    "YTest = torch.cat(YTest)\n",
    "YhatTest = torch.cat(YhatTest)\n",
    "print(f'Test loss: {criterion(yhat,batch.y):.3f}')\n",
    "MeanAE = (YTest-YhatTest).abs().mean()*Ystd\n",
    "print(f'MeanAE: {MeanAE:.3f} kJ/mol')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
