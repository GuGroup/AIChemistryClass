{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ACwXgb5bvmL"
   },
   "source": [
    "### Dataset\n",
    "Below is the paper that contains the model that we will use. If you are interested, have a look.\n",
    "\n",
    "Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules\r\n",
    "Rafael Gómez-Bombarelli†#Orcid, Jennifer N. Wei‡#Orcid, David Duvenaud¶#, José Miguel Hernández-Lobato§#, Benjamín Sánchez-Lengeling‡, Dennis Sheberla‡Orcid, Jorge Aguilera-Iparraguirre†, Timothy D. Hirzel†, Ryan P. Adams∇∥, and Alán Aspuru-Guzik*‡⊥https://doi.org/10.1021/acscentsci.7b005727."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAizZzgTb0Bj"
   },
   "source": [
    "### Data Loader\n",
    "Here we will use ZINC data set with smiles and quantitative estimatte of druglikeness (QED). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>qed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1</td>\n",
       "      <td>0.941112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...</td>\n",
       "      <td>0.626105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...</td>\n",
       "      <td>0.716225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...</td>\n",
       "      <td>0.809572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC[NH+](CC)[C@](C)(CC)[C@H](O)c1cscc1Br</td>\n",
       "      <td>0.827150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles       qed\n",
       "0       C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1  0.941112\n",
       "1  N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...  0.626105\n",
       "2  CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...  0.716225\n",
       "3  N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...  0.809572\n",
       "4            CC[NH+](CC)[C@](C)(CC)[C@H](O)c1cscc1Br  0.827150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('HW20.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "Below is the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2888,
     "status": "ok",
     "timestamp": 1666591848032,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "fh5RcfPlWmyv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "class Data(Dataset):\n",
    "  def __init__(self, data_path,string_length=120,ndata = 1000):\n",
    "    self.charset = [' ', '#', '(', ')', '+', '-', '/', '1', '2', '3', '4', '5', '6', '7',\n",
    "    '8', '=', '@', 'B', 'C', 'F', 'H', 'I', 'N', 'O', 'P', 'S', '[', '\\\\', ']',\n",
    "    'c', 'l', 'n', 'o', 'r', 's']\n",
    "    self.chartnp = np.array(self.charset)\n",
    "    self.string_length = string_length\n",
    "    self.num_char = len(self.charset)\n",
    "\n",
    "    df = pd.read_csv(data_path)\n",
    "    data = df.numpy()\n",
    "    smiles = df.smiles.to_list()\n",
    "    Ys_raw = df.iloc[:,1].to_numpy()\n",
    "\n",
    "    self.Ys = torch.Tensor(Ys_raw)\n",
    "    self.Xs = torch.Tensor(self.one_hot_encode(smiles))\n",
    "    self.smiles = smiles\n",
    "      \n",
    "  def one_hot_encode(self, smiles):\n",
    "    processed = np.zeros((len(smiles),self.string_length,self.num_char))\n",
    "    for i,s in tqdm(enumerate(smiles),total=len(smiles)):\n",
    "      for j,ss in enumerate(s):# get one hot encoding\n",
    "        processed[i,j,self.charset.index(ss)] = 1\n",
    "      processed[i,j+1:,0] = 1\n",
    "    return processed\n",
    "\n",
    "  def one_hot_to_smiles(self, z):\n",
    "    z = self.chartnp[np.argmax(z,axis=2)]\n",
    "    z1 = []\n",
    "    for r in tqdm(z):\n",
    "      z1.append(''.join(r).split()[0])\n",
    "    return z1\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.Xs.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    y = self.Ys[idx]\n",
    "    x = self.Xs[idx,:,:]\n",
    "    return idx, y,x\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# Loading data\n",
    "print('loading data...',end=''); t = time()\n",
    "data = Data('HW20.csv',ndata=1000)\n",
    "print('completed', time()-t,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZJI2AAob31p"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1666591851059,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "NTCcaMBOZJrb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Conv_Encoder(nn.Module):\n",
    "  def __init__(self, vocab_len):\n",
    "    super(Conv_Encoder,self).__init__()\n",
    "    self.conv_1 = nn.Conv1d(120, 9, kernel_size=9)\n",
    "    self.bn_1 = nn.BatchNorm1d(9)\n",
    "    self.conv_2 = nn.Conv1d(9, 9, kernel_size=9)\n",
    "    self.bn_2 = nn.BatchNorm1d(9)\n",
    "    self.conv_3 = nn.Conv1d(9, 10, kernel_size=11)\n",
    "    self.bn_3 = nn.BatchNorm1d(10)\n",
    "    self.fc_1 = nn.Linear(10*(vocab_len-26),435)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.bn_4 = nn.BatchNorm1d(435)\n",
    "  def forward(self, x):\n",
    "    batch_size = x.shape[0]\n",
    "    x = x.swapaxes(1,2)\n",
    "    x = self.relu(self.conv_1(x))\n",
    "    x = self.bn_1(x)\n",
    "    x = self.relu(self.conv_2(x))\n",
    "    x = self.bn_2(x)\n",
    "    x = self.relu(self.conv_3(x))\n",
    "    x = self.bn_3(x)\n",
    "    x = x.reshape(batch_size, -1)\n",
    "    x = self.relu(self.fc_1(x))\n",
    "    x = self.bn_4(x)\n",
    "    return x\n",
    "  \n",
    "class GRU_Decoder(nn.Module):\n",
    "  def __init__(self, vocab_size):\n",
    "    super(GRU_Decoder,self).__init__()\n",
    "    self.fc_1 = nn.Linear(292, 292)\n",
    "    self.bn_1 = nn.BatchNorm1d(292)\n",
    "    self.gru = nn.GRU(292, 501, 3, batch_first=True)\n",
    "    self.bn_2 = nn.BatchNorm1d(501)\n",
    "    self.fc_2 = nn.Linear(501, vocab_size)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, z):\n",
    "    batch_size = z.shape[0]\n",
    "    z = self.relu(self.fc_1(z))\n",
    "    z = self.bn_1(z)\n",
    "    z = z.unsqueeze(1).repeat(1, 120, 1)\n",
    "    z_out, hidden = self.gru(z)\n",
    "    z_out = self.bn_2(z_out.swapaxes(1,2)).swapaxes(1,2)\n",
    "    z_logit = self.fc_2(z_out)\n",
    "    return z_logit\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Predictor, self).__init__()\n",
    "    self.pred_fc1 = nn.Linear(292, 100)\n",
    "    self.pred_fc2 = nn.Linear(100, 1)\n",
    "  def forward(self, mu):\n",
    "    z = F.selu(self.pred_fc1(mu))\n",
    "    z = self.pred_fc2(z)\n",
    "    return F.sigmoid(z)\n",
    "\n",
    "class Molecule_VAE(nn.Module):\n",
    "  def __init__(self, vocab_size = 35, latent_dim=292):\n",
    "    super(Molecule_VAE, self).__init__()\n",
    "    self.encoder = Conv_Encoder(vocab_size)\n",
    "    self.decoder = GRU_Decoder(vocab_size)\n",
    "    self.predictor = Predictor(latent_dim)\n",
    "    self.enc_mu = nn.Linear(435,292)\n",
    "    self.enc_log_var = nn.Linear(435,292)\n",
    "      \n",
    "  def _sample_latent(self, h_enc):\n",
    "    \"\"\"\n",
    "    Return the latent normal sample z ~ N(mu, sigma^2)\n",
    "    \"\"\"\n",
    "    mu = self.enc_mu(h_enc)\n",
    "    log_var = self.enc_log_var(h_enc)\n",
    "    sig = torch.exp(0.5*log_var)\n",
    "    # Reparameterization trick\n",
    "    std_z = torch.randn(sig.size()).float().to(mu.device) \n",
    "    z = mu + sig * std_z\n",
    "    var = torch.exp(log_var)\n",
    "    return z, mu, var\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"Forward Function which passes the data through entire model\"\"\"\n",
    "    self.h_enc = self.encoder(x.swapaxes(1,2))\n",
    "    z, mu, var = self._sample_latent(self.h_enc)\n",
    "    y = self.predictor(mu)\n",
    "    recon_x = self.decoder(z)\n",
    "    return recon_x, mu, var, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQzQHiMsb6ly"
   },
   "source": [
    "# Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1666591855688,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "URHJwy54YA6N"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "def use_model(data_loader, model, criterion, optimizer, i_iter, mode, name = None):\n",
    "  assert mode in ['train','predict']\n",
    "  #switch to model mode\n",
    "  if mode == 'train':\n",
    "    model.train()\n",
    "  elif mode == 'predict':\n",
    "    model.eval()\n",
    "\n",
    "  X_true = []\n",
    "  X_pred = [] \n",
    "  Y_true = []\n",
    "  Y_pred = []\n",
    "  mus = []\n",
    "  idxss=[]\n",
    "  losses = []\n",
    "\n",
    "  for idxs, ys,xs in data_loader: # loop for each batch\n",
    "    # move input to cuda\n",
    "    if next(model.parameters()).is_cuda:\n",
    "      xs = xs.to(device='cuda')\n",
    "      ys = ys.to(device='cuda')\n",
    "        \n",
    "    #compute output\n",
    "    if mode == 'train':\n",
    "      recon_batch, mu, var, y_p = model(xs)\n",
    "    elif mode == 'predict':\n",
    "      with torch.no_grad(): # it does not compute the gradient. so it's faster\n",
    "        recon_batch, mu, var, y_p = model(xs)\n",
    "    # loss\n",
    "      \n",
    "    loss = criterion(recon_batch, xs, mu, var,ys,y_p)\n",
    "    \n",
    "    # Backward propagation\n",
    "    if mode == 'train':\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    \n",
    "    losses.append(float(loss))\n",
    "    X_pred += recon_batch.cpu().tolist()\n",
    "    Y_pred += y_p.cpu().tolist()\n",
    "    X_true += xs.cpu().tolist()\n",
    "    Y_true += ys.cpu().tolist() # list concatenation\n",
    "    mus += mu.cpu().tolist()\n",
    "    idxss += idxs.tolist()\n",
    "  return X_pred,X_true,Y_pred,Y_true,np.mean(losses),mus,idxss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acZMDyqAcE8N"
   },
   "source": [
    "# Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 386626,
     "status": "error",
     "timestamp": 1666592258253,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "DR0Crd-rcDuy",
    "outputId": "7f6989c1-a7b0-47c8-f0d8-c95a1e49271b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "def loss_function(recon_x, x, mu, var,y_true,y_pred):\n",
    "    BCE = F.cross_entropy(recon_x.swapaxes(1,2), x.swapaxes(1,2), reduction='mean')\n",
    "    KLD = 0.5 * torch.mean(-torch.log(var) - 1 + mu.pow(2) + var)\n",
    "    MSE = torch.mean((y_true-y_pred)**2)\n",
    "    return BCE + 1e-6*KLD + 1e-6*0.5*MSE\n",
    "\n",
    "################################ Input ####################################\n",
    "# data\n",
    "\n",
    "\n",
    "# Training\n",
    "batch_size = 64\n",
    "lr = 0.0003\n",
    "nepochs = 1000\n",
    "cuda = True\n",
    "seed = 1234\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "data_train, data_test = random_split(data,[0.90,0.1]) \n",
    "dataloader_train = DataLoader(data_train, batch_size=64, shuffle=True)\n",
    "dataloader_test = DataLoader(data_test, batch_size=64, shuffle=True)\n",
    "\n",
    "#build model\n",
    "model = Molecule_VAE()\n",
    "if cuda:\n",
    "  if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model,device_ids=[0])\n",
    "  model.cuda()\n",
    "\n",
    "## Training\n",
    "criterion = loss_function # \n",
    "optimizer = optim.Adam(model.parameters(),lr,weight_decay= 0) # 0 means no penalty\n",
    "best_train_loss = float('inf')\n",
    "for i_iter in range(nepochs): # epochs\n",
    "  X_pred,X_true,Y_pred,Y_true,losses,mus,idxss = use_model(train_loader,model,criterion,optimizer,i_iter,'train') # training model\n",
    "  print('Train loss [%03d]: %.2e'%(i_iter, losses),end='')\n",
    "  if losses < best_train_loss: # if validation set error is lower than previous best\n",
    "    best_train_loss = losses\n",
    "    print('<-Best')\n",
    "    torch.save(model.state_dict(),'Weights.pth.tar') # we save the data\n",
    "  else: print('')\n",
    "  \n",
    "model.load_state_dict(torch.load('Weights.pth.tar'))\n",
    "X_pred,X_true,Y_pred,Y_true,losses,mus,idxss = use_model(train_loader,model,criterion,optimizer,i_iter,'predict') # training model\n",
    "X_true = np.array(X_true)\n",
    "X_pred = F.softmax(torch.Tensor(X_pred),dim=2).numpy()\n",
    "Y_true = np.array(Y_true)\n",
    "Y_pred = np.array(Y_pred)\n",
    "\n",
    "for t,p in zip(Y_true[:10],Y_pred[:10]):\n",
    "  print(t,p)\n",
    "  \n",
    "for s_pred,s_true in zip(data.one_hot_to_smiles(X_pred[:10,:,:]),data.one_hot_to_smiles(X_true[:10,:,:])):\n",
    "  print(s_true,'\\n',s_pred,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2PxxwoLKRRv"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('Weights.pth.tar'))\n",
    "X_pred,X_true,Y_pred,Y_true,losses,mus,idxss = use_model(train_loader,model,criterion,optimizer,i_iter,'predict') # training model\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "mus = np.array(mus)\n",
    "pca = PCA(2)\n",
    "zs = pca.fit_transform(mus)\n",
    "plt.scatter(zs[:,0],zs[:,1],c=Y_true)\n",
    "# sample\n",
    "z = torch.Tensor(pca.inverse_transform([[0,10]])).cuda()\n",
    "data.one_hot_to_smiles(model.decoder(z).cpu().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPoswM6gzvs4pZTSV3PPwBr",
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
