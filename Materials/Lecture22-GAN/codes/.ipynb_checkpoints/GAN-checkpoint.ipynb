{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>H</th>\n",
       "      <th>He</th>\n",
       "      <th>Li</th>\n",
       "      <th>Be</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>F</th>\n",
       "      <th>...</th>\n",
       "      <th>Mt</th>\n",
       "      <th>Ds</th>\n",
       "      <th>Rg</th>\n",
       "      <th>Cn</th>\n",
       "      <th>Nh</th>\n",
       "      <th>Fl</th>\n",
       "      <th>Mc</th>\n",
       "      <th>Lv</th>\n",
       "      <th>Ts</th>\n",
       "      <th>Og</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Si1 C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sc3 Sn1 B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Na1 Ga1 Te2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nb1 In1 S2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La1 N1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       formula    H   He   Li   Be    B    C    N    O    F  ...   Mt   Ds  \\\n",
       "0       Si1 C1  0.0  0.0  0.0  0.0  0.0  0.5  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1   Sc3 Sn1 B1  0.0  0.0  0.0  0.0  0.2  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2  Na1 Ga1 Te2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3   Nb1 In1 S2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4       La1 N1  0.0  0.0  0.0  0.0  0.0  0.0  0.5  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "    Rg   Cn   Nh   Fl   Mc   Lv   Ts   Og  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('HW21.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAizZzgTb0Bj"
   },
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1667373059652,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "fh5RcfPlWmyv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...completed 0.22204065322875977 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from time import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data(Dataset):\n",
    "  def __init__(self):\n",
    "    df = pd.read_csv('HW21.csv')\n",
    "    self.Xs = torch.Tensor(df.iloc[:,1:].to_numpy())\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.Xs.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x = self.Xs[idx,:]\n",
    "    return idx, x\n",
    "\n",
    "# Loading data\n",
    "print('loading data...',end=''); t = time()\n",
    "data = Data()\n",
    "dataloader = DataLoader(data, batch_size=64, shuffle=True)\n",
    "print('completed', time()-t,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZJI2AAob31p"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667373391608,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "NTCcaMBOZJrb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# adaopted from\n",
    "# https://github.com/Zeleni9/pytorch-wgan/blob/master/models/wgan_gradient_penalty.py\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_module = nn.Sequential(\n",
    "            # Z latent vector 128\n",
    "            nn.Linear(128,128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128,118),\n",
    "            nn.Softmax())\n",
    "    def forward(self, x):\n",
    "        return  self.main_module(x)\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_module = nn.Sequential(\n",
    "            nn.Linear(118,128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main_module(x)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#build model\n",
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQzQHiMsb6ly"
   },
   "source": [
    "# Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667373618273,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "URHJwy54YA6N"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "\n",
    "def calculate_gradient_penalty(D, real_xs, fake_xs, lambdaa=10):\n",
    "\n",
    "    eta = torch.FloatTensor(real_xs.shape[0],118).uniform_(0,1)\n",
    "    eta = eta.to(device='cuda')\n",
    "\n",
    "    interpolated = eta * real_xs + ((1 - eta) * fake_xs)\n",
    "\n",
    "    # calculate probability of interpolated examples\n",
    "    prob_interpolated = D(interpolated)\n",
    "\n",
    "    # calculate gradients of probabilities with respect to examples\n",
    "    gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                            grad_outputs=torch.ones(prob_interpolated.size()).cuda(),\n",
    "                            create_graph=True, retain_graph=True)[0]\n",
    "    grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambdaa\n",
    "    return grad_penalty\n",
    "\n",
    "def use_model(data_loader, D,G, criterion, Doptimizer, Goptimizer, i_iter,  name = None):\n",
    "  #switch to model mode\n",
    "  G.train()\n",
    "  D.train()\n",
    "  D_losses = []\n",
    "  G_losses = []\n",
    "  WasDs = []\n",
    "  one = torch.tensor(1, dtype=torch.float)\n",
    "  mone = one * -1\n",
    "  if next(D.parameters()).is_cuda:\n",
    "    one = one.to(device='cuda')\n",
    "    mone = mone.to(device='cuda')\n",
    "  for idxs, xs in data_loader: # loop for each batch\n",
    "    ### training discriminator\n",
    "    for p in D.parameters():\n",
    "        p.requires_grad = True\n",
    "    z = torch.randn(xs.shape[0], 128)\n",
    "    # move input to cuda\n",
    "    if next(D.parameters()).is_cuda:\n",
    "      xs = xs.to(device='cuda')\n",
    "      z = z.to(device='cuda')\n",
    "    #compute output\n",
    "    # real data loss\n",
    "    Dreal_loss = D(xs)\n",
    "    fake_xs = G(z)\n",
    "    Dfake_loss = D(fake_xs)\n",
    "    # real data back propagation\n",
    "    Doptimizer.zero_grad()\n",
    "    Dreal_loss = Dreal_loss.mean()\n",
    "    Dreal_loss.backward(mone, retain_graph=True)\n",
    "    Dfake_loss = Dfake_loss.mean()\n",
    "    Dfake_loss.backward(one, retain_graph=True)\n",
    "    gradient_penalty = calculate_gradient_penalty(D, xs, fake_xs)\n",
    "    gradient_penalty.backward(retain_graph=True)\n",
    "    Doptimizer.step()\n",
    "    # recording loss\n",
    "    d_loss = Dreal_loss - Dfake_loss + gradient_penalty\n",
    "    WasD = Dreal_loss - Dfake_loss\n",
    "    D_losses.append(float(d_loss))\n",
    "    WasDs.append(float(WasD))\n",
    "    \n",
    "    ### training generator\n",
    "    for p in D.parameters():\n",
    "        p.requires_grad = False\n",
    "    z = torch.randn(xs.shape[0], 128)\n",
    "    # move input to cuda\n",
    "    if next(D.parameters()).is_cuda:\n",
    "      z = z.to(device='cuda')\n",
    "\n",
    "    fake_xs = G(z)\n",
    "    Dfake_loss = D(fake_xs)\n",
    "    Goptimizer.zero_grad()\n",
    "    Dfake_loss = Dfake_loss.mean()\n",
    "    Dfake_loss.backward(mone)\n",
    "    Goptimizer.step()\n",
    "    g_loss = Dfake_loss\n",
    "    G_losses.append(float(g_loss))\n",
    "\n",
    "  return np.mean(D_losses),np.mean(G_losses),np.mean(WasDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acZMDyqAcE8N"
   },
   "source": [
    "# Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 596240,
     "status": "error",
     "timestamp": 1667374216670,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "DR0Crd-rcDuy",
    "outputId": "bea157a6-c219-4b1d-c868-dc9b7332d146"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1234\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m dataloader_train \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mdata_train\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m## Training\u001b[39;00m\n\u001b[0;32m     19\u001b[0m Doptimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(D\u001b[38;5;241m.\u001b[39mparameters(),lr,weight_decay\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# 0 means no penalty\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "################################ Input ####################################\n",
    "# data\n",
    "TrainValTeSplitst = [1.0, 0.0, 0.0]\n",
    "\n",
    "# Training\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "nepochs = 1000\n",
    "cuda = True\n",
    "seed = 1234\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "## Training\n",
    "Doptimizer = optim.Adam(D.parameters(),lr,weight_decay= 0) # 0 means no penalty\n",
    "Goptimizer = optim.Adam(G.parameters(),lr,weight_decay= 0) # 0 means no penalty\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "for i_iter in range(nepochs): # epochs\n",
    "  Dloss, Gloss, WD = use_model(dataloader_train,D,G,None,Doptimizer,Goptimizer,i_iter) # training model\n",
    "  print('Train loss [%03d]: %10.2e %10.2e %10.2e'%(i_iter, Dloss, Gloss, WD))\n",
    "  torch.save(D.state_dict(),'DW.pth.tar') # we save the data\n",
    "  torch.save(G.state_dict(),'GW.pth.tar') # we save the data\n",
    "  \n",
    "G.load_state_dict(torch.load('GW.pth.tar'))\n",
    "G.eval()\n",
    "z = torch.randn(64, 128)\n",
    "# move input to cuda\n",
    "if next(G.parameters()).is_cuda:\n",
    "  z = z.to(device='cuda')\n",
    "with torch.no_grad(): # it does not compute the gradient. so it's faster\n",
    "  fake_xs = G(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667374236454,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "M2PxxwoLKRRv"
   },
   "outputs": [],
   "source": [
    "z = torch.randn(64, 128)\n",
    "# move input to cuda\n",
    "if next(G.parameters()).is_cuda:\n",
    "  z = z.to(device='cuda')\n",
    "with torch.no_grad(): # it does not compute the gradient. so it's faster\n",
    "  fake_xs = G(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1667374512666,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "doHei4quP9VH",
    "outputId": "0c3893ce-1d02-4252-e09d-a3f251a3515a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re1.00 \n",
      "C0.02 Re0.98 \n",
      "Re1.00 \n",
      "Re0.99 \n",
      "C0.07 Re0.93 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "C0.05 Re0.95 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "C0.07 Re0.93 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "C0.02 Re0.98 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re0.99 \n",
      "Re0.99 \n",
      "Re1.00 \n",
      "C0.03 Re0.97 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "C0.01 Re0.99 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "C0.01 Re0.99 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "C0.09 Re0.91 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n",
      "Re1.00 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "chemical_symbols = [\n",
    "    # 0\n",
    "    'X',\n",
    "    # 1\n",
    "    'H', 'He',\n",
    "    # 2\n",
    "    'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne',\n",
    "    # 3\n",
    "    'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar',\n",
    "    # 4\n",
    "    'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
    "    'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr',\n",
    "    # 5\n",
    "    'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd',\n",
    "    'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
    "    # 6\n",
    "    'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy',\n",
    "    'Ho', 'Er', 'Tm', 'Yb', 'Lu',\n",
    "    'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi',\n",
    "    'Po', 'At', 'Rn',\n",
    "    # 7\n",
    "    'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk',\n",
    "    'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr',\n",
    "    'Rf', 'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc',\n",
    "    'Lv', 'Ts', 'Og']\n",
    "xs = np.array(fake_xs.tolist())\n",
    "xs[xs <0.01] = 0\n",
    "for j in range(xs.shape[0]):\n",
    "  nonzero = np.where(xs[j,:])[0]\n",
    "  s = ''\n",
    "  for i in nonzero:\n",
    "    s += chemical_symbols[i-1] + '%.2f'%xs[j,i] +' '\n",
    "  print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Data\n",
    "For your information, the code below was used to make the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.ext.matproj import MPRester\n",
    "import numpy as np\n",
    "from ase.data import chemical_symbols\n",
    "from pymatgen.core import Composition\n",
    "import csv\n",
    "\n",
    "with MPRester(\"gv5swR0lIWsfLsGk\") as m:\n",
    "    docs = m.query({},{'pretty_formula':True,'icsd_ids':True})\n",
    "    raw_data = [(doc['pretty_formula'],doc['icsd_ids']) for doc in docs]\n",
    "\n",
    "new_data = {}\n",
    "for f,v in raw_data:\n",
    "    if len(v) != 0:\n",
    "        c = Composition(f)\n",
    "        new_data[str(c)] = dict(c.fractional_composition)\n",
    "\n",
    "sym_map = {}\n",
    "for i,s in enumerate(chemical_symbols):\n",
    "    sym_map[s] = i -1\n",
    "\n",
    "data = np.zeros((len(new_data),len(chemical_symbols)-1))\n",
    "names = []\n",
    "for i,(name,d) in enumerate(new_data.items()):\n",
    "    names.append(name)\n",
    "    for k,v in d.items():\n",
    "        data[i,sym_map[str(k)]] = v\n",
    "\n",
    "data_to_copy = [['formula']+chemical_symbols[1:]]\n",
    "for n, r in zip(names,data):\n",
    "    data_to_copy.append([n]+r.tolist())\n",
    "\n",
    "with open('data.csv','w',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for l in data_to_copy:\n",
    "        writer.writerow(l)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPlxRazEkOwKuZCQ/GYbkmH",
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
