{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset involves the composition data from materials project. Compositions of the existing, previously synthesized materials are described here. We will train a model that can generate a composition similar the previously synthesized materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Example_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAizZzgTb0Bj"
   },
   "source": [
    "### Data Loader\n",
    "Simple data loader that loads the composition. Note that we do not have any labels. Just the X. The goal of the GAN model is to create the a vector similar to real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1667373059652,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "fh5RcfPlWmyv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from time import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data(Dataset):\n",
    "  def __init__(self):\n",
    "    df = pd.read_csv('Example_data.csv')\n",
    "    self.Xs = torch.Tensor(df.iloc[:,1:].to_numpy())\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.Xs.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x = self.Xs[idx,:]\n",
    "    return idx, x\n",
    "\n",
    "# Loading data\n",
    "print('loading data...',end=''); t = time()\n",
    "data = Data()\n",
    "dataloader = DataLoader(data, batch_size=64, shuffle=True)\n",
    "print('completed', time()-t,'sec')\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZJI2AAob31p"
   },
   "source": [
    "### Model\n",
    "Here we have a simple model that calculates the composition using the softmax function. and also the disciminator which is used to create some abstract distribution of the data. We are trying to make the distribution from the fake and the real data similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667373391608,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "NTCcaMBOZJrb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_module = nn.Sequential(\n",
    "            # Z latent vector 128\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,118),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return  self.main_module(x)\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_module = nn.Sequential(\n",
    "            nn.Linear(118,128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128,1))\n",
    "    def forward(self, x):\n",
    "        return self.main_module(x)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#build model\n",
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQzQHiMsb6ly"
   },
   "source": [
    "### Using Model\n",
    "This function contains the utilization of the model.\n",
    "Note the training process. The training consists of two phases, where the Discriminator is trained first, followed by the generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667373618273,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "URHJwy54YA6N"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "\n",
    "def calculate_gradient_penalty(D, xr, xf):\n",
    "    eta = torch.rand(xr.shape[0],1).to(device=device)\n",
    "    interpolated = eta * xr + (1 - eta) * xf\n",
    "    interpolated.requires_grad_()\n",
    "    prob_interpolated = D(interpolated)\n",
    "    gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                            grad_outputs=torch.ones_like(prob_interpolated).to(device=device),\n",
    "                            create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return grad_penalty\n",
    "\n",
    "def use_model(data_loader, D,G, criterion, Doptimizer, Goptimizer, i_iter,  name = None):\n",
    "  #switch to model mode\n",
    "  G.train()\n",
    "  D.train()\n",
    "  D_losses = []\n",
    "  G_losses = []\n",
    "  WasDs = []\n",
    "  for idxs, xr in data_loader: # loop for each batch\n",
    "    ### 1. training discriminator\n",
    "    z = torch.randn(xr.shape[0], 128)\n",
    "    z = z.to(device=device)\n",
    "    \n",
    "    xr = xr.to(device=device)\n",
    "    xf = G(z).detach()\n",
    "      \n",
    "    Dreal_loss = D(xr).mean()\n",
    "    Dfake_loss = D(xf).mean()\n",
    "    gp = calculate_gradient_penalty(D, xr, xf.detach())\n",
    "      \n",
    "    D_loss = - Dreal_loss + Dfake_loss + 10 * gp\n",
    "      \n",
    "    Doptimizer.zero_grad()\n",
    "    D_loss.backward()\n",
    "    Doptimizer.step()\n",
    "\n",
    "    D_losses.append(float(D_loss.item()))\n",
    "    WasDs.append(abs(float((Dreal_loss - Dfake_loss).item())))\n",
    "\n",
    "    ### 2. training generator\n",
    "    z = torch.randn(xr.shape[0], 128).to(device=device)\n",
    "    xf = G(z)\n",
    "    G_loss = - D(xf).mean()\n",
    "      \n",
    "    Goptimizer.zero_grad()\n",
    "    G_loss.backward()\n",
    "    Goptimizer.step()\n",
    "    \n",
    "    G_losses.append(float(G_loss.item()))\n",
    "\n",
    "  return np.mean(D_losses),np.mean(G_losses),np.mean(WasDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acZMDyqAcE8N"
   },
   "source": [
    "### Training\n",
    "Here is the code for training the model. You will have to train the model for 1000 epochs to get a reliable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 596240,
     "status": "error",
     "timestamp": 1667374216670,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "DR0Crd-rcDuy",
    "outputId": "bea157a6-c219-4b1d-c868-dc9b7332d146"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "## Training\n",
    "Doptimizer = optim.Adam(D.parameters(),lr=0.001)\n",
    "Goptimizer = optim.Adam(G.parameters(),lr=0.001)\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "for i_iter in range(1000): # epochs\n",
    "  Dloss, Gloss, WD = use_model(dataloader,D,G,None,Doptimizer,Goptimizer,i_iter) # training model\n",
    "  print('Train loss [%03d]: D_loss %10.2e G_loss %10.2e WasD %10.2e'%(i_iter, Dloss, Gloss, WD))\n",
    "\n",
    "torch.save(D.state_dict(),'DW.pth.tar') # we save the data\n",
    "torch.save(G.state_dict(),'GW.pth.tar') # we save the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model\n",
    "Here we generate a random composition that are similar to the realistic materials' composition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1667374512666,
     "user": {
      "displayName": "에너지공학부/구근호",
      "userId": "09292163357270917481"
     },
     "user_tz": -540
    },
    "id": "doHei4quP9VH",
    "outputId": "0c3893ce-1d02-4252-e09d-a3f251a3515a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "G.eval()\n",
    "z = torch.randn(64, 128).to(device=device)\n",
    "with torch.no_grad(): # it does not compute the gradient. so it's faster\n",
    "  fake_xs = G(z)\n",
    "\n",
    "chemical_symbols = [\n",
    "    # 0\n",
    "    'X',\n",
    "    # 1\n",
    "    'H', 'He',\n",
    "    # 2\n",
    "    'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne',\n",
    "    # 3\n",
    "    'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar',\n",
    "    # 4\n",
    "    'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
    "    'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr',\n",
    "    # 5\n",
    "    'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd',\n",
    "    'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
    "    # 6\n",
    "    'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy',\n",
    "    'Ho', 'Er', 'Tm', 'Yb', 'Lu',\n",
    "    'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi',\n",
    "    'Po', 'At', 'Rn',\n",
    "    # 7\n",
    "    'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk',\n",
    "    'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr',\n",
    "    'Rf', 'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc',\n",
    "    'Lv', 'Ts', 'Og']\n",
    "xs = np.array(fake_xs.tolist())\n",
    "xs[xs <0.01] = 0\n",
    "for j in range(xs.shape[0]):\n",
    "  nonzero = np.where(xs[j,:])[0]\n",
    "  s = ''\n",
    "  for i in nonzero:\n",
    "    s += chemical_symbols[i-1] + '%.2f'%xs[j,i] +' '\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Data\n",
    "For your information, the code below was used to make the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.ext.matproj import MPRester\n",
    "import numpy as np\n",
    "from ase.data import chemical_symbols\n",
    "from pymatgen.core import Composition\n",
    "import csv\n",
    "\n",
    "with MPRester(\"gv5swR0lIWsfLsGk\") as m:\n",
    "    docs = m.query({},{'pretty_formula':True,'icsd_ids':True})\n",
    "    raw_data = [(doc['pretty_formula'],doc['icsd_ids']) for doc in docs]\n",
    "\n",
    "new_data = {}\n",
    "for f,v in raw_data:\n",
    "    if len(v) != 0:\n",
    "        c = Composition(f)\n",
    "        new_data[str(c)] = dict(c.fractional_composition)\n",
    "\n",
    "sym_map = {}\n",
    "for i,s in enumerate(chemical_symbols):\n",
    "    sym_map[s] = i -1\n",
    "\n",
    "data = np.zeros((len(new_data),len(chemical_symbols)-1))\n",
    "names = []\n",
    "for i,(name,d) in enumerate(new_data.items()):\n",
    "    names.append(name)\n",
    "    for k,v in d.items():\n",
    "        data[i,sym_map[str(k)]] = v\n",
    "\n",
    "data_to_copy = [['formula']+chemical_symbols[1:]]\n",
    "for n, r in zip(names,data):\n",
    "    data_to_copy.append([n]+r.tolist())\n",
    "\n",
    "with open('data.csv','w',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for l in data_to_copy:\n",
    "        writer.writerow(l)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPlxRazEkOwKuZCQ/GYbkmH",
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
